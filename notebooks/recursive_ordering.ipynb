{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1934827/1551590045.py\", line 5, in <module>\n",
      "    from notebook_setup import device, smooth_graph, create_new_set_of_models, train_models_and_get_histories, update_dict\n",
      "  File \"/home/amli/oslow/notebooks/notebook_setup.py\", line 22, in <module>\n",
      "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
      "/home/amli/oslow/notebooks/notebook_setup.py:22: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from notebook_setup import device, smooth_graph, create_new_set_of_models, train_models_and_get_histories, update_dict\n",
    "from oslow.models.oslow import OSlow\n",
    "from oslow.data.synthetic.graph_generator import GraphGenerator\n",
    "from oslow.data.synthetic.utils import RandomGenerator\n",
    "from oslow.data.synthetic.parametric import AffineParametericDataset\n",
    "from oslow.models.normalization import ActNorm\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a causal graph using the GraphGenerator class. Here, we specify the number of nodes (3) and enforce a specific ordering [1, 0, 2]. This graph will be used as the ground truth for our causal discovery experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_generator = GraphGenerator(\n",
    "    num_nodes=3,\n",
    "    seed=0,\n",
    "    graph_type=\"full\",\n",
    "    enforce_ordering=[1, 0, 2],\n",
    ")\n",
    "graph = graph_generator.generate_dag()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we generate synthetic data based on the causal graph. We create an AffineParametericDataset \n",
    "with sinusoidal links between variables. This dataset will be used to train our OSlow models and \n",
    "test our causal discovery strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "gaussian_noise_generator = RandomGenerator('normal', seed=10, loc=0, scale=1)\n",
    "link_generator = RandomGenerator('uniform', seed=110, low=1, high=1)\n",
    "\n",
    "dset_sinusoidal = AffineParametericDataset(\n",
    "    num_samples=num_samples,\n",
    "    graph_generator=graph_generator,  # Not graph, requires a GraphGenerator object that generates the DAG\n",
    "    noise_generator=gaussian_noise_generator,\n",
    "    link_generator=link_generator,\n",
    "    link=\"sinusoid\",\n",
    "    perform_normalization=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell defines the settings for our OSlow models and their training process. We specify the model \n",
    "architecture (additive or not, number of transforms, normalization method) and training parameters \n",
    "(batch size, learning rate, number of epochs). These settings will be used for all OSlow models we create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_instantiation_setting = dict(\n",
    "    additive = False,\n",
    "    num_transforms = 1,\n",
    "    normalization = ActNorm,\n",
    "    base_distribution = torch.distributions.Normal(loc=0, scale=1),\n",
    "    use_standard_ordering=False,\n",
    ")\n",
    "\n",
    "base_training_setting = dict(\n",
    "    batch_size=512,\n",
    "    lr=0.005,\n",
    "    epoch_count=33,\n",
    "    use_standard_ordering=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a warm-up model that can be used for other initializations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_permutation_matrix(size):\n",
    "    perm = torch.randperm(size)\n",
    "    return torch.eye(size)[perm]\n",
    "\n",
    "def warm_up_oslow(data, base_model_instantiation_setting, base_training_setting, num_warmup_epochs=50):\n",
    "    # Create a single OSlow model\n",
    "    warmup_model = create_new_set_of_models(\n",
    "        single_ordering='012',  # This ordering doesn't matter as we'll use random permutations\n",
    "        **base_model_instantiation_setting\n",
    "    )\n",
    "\n",
    "    # Modify training settings for warm-up\n",
    "    warmup_training_setting = update_dict(\n",
    "        base_training_setting,\n",
    "        epoch_count=num_warmup_epochs,\n",
    "        use_standard_ordering=False  # We'll provide random permutations\n",
    "    )\n",
    "\n",
    "    # Custom training loop for warm-up\n",
    "    optimizer = torch.optim.Adam(warmup_model.parameters(), lr=warmup_training_setting['lr'])\n",
    "    for epoch in range(num_warmup_epochs):\n",
    "        for batch in torch.utils.data.DataLoader(data, batch_size=warmup_training_setting['batch_size'], shuffle=True):\n",
    "            optimizer.zero_grad()\n",
    "            perm_mat = generate_random_permutation_matrix(3).to(batch.device)\n",
    "            loss = -warmup_model.log_prob(batch, perm_mat=perm_mat).mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return warmup_model\n",
    "\n",
    "def transfer_weights(source_model, target_model):\n",
    "    target_dict = target_model.state_dict()\n",
    "    source_dict = source_model.state_dict()\n",
    "    for name in target_dict:\n",
    "        if name in source_dict:\n",
    "            target_dict[name].data.copy_(source_dict[name].data)\n",
    "    target_model.load_state_dict(target_dict)\n",
    "\n",
    "\n",
    "def create_and_train_oslow_model_with_warmup(ordering, data, warmup_model, base_model_instantiation_setting, base_training_setting):\n",
    "    # Create a new model with the specified ordering\n",
    "    model = create_new_set_of_models(\n",
    "        single_ordering=ordering,\n",
    "        **base_model_instantiation_setting\n",
    "    )\n",
    "\n",
    "    # Transfer weights from the warm-up model\n",
    "    transfer_weights(warmup_model, model)\n",
    "\n",
    "    # Train the model\n",
    "    history = train_models_and_get_histories(\n",
    "        {ordering: model},\n",
    "        data,\n",
    "        **base_training_setting\n",
    "    )\n",
    "\n",
    "    return model, history[ordering]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to modify this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_oslow_model_with_start_covariate(start_covariate, dset):\n",
    "    ordering = ''.join(str(i) for i in ([start_covariate] + [j for j in range(3) if j != start_covariate]))\n",
    "    # by specifying single_ordering, we only make one model\n",
    "    print(f\"Creating model with ordering: {ordering}\")\n",
    "    model = create_new_set_of_models(\n",
    "        single_ordering=ordering,\n",
    "        **base_model_instantiation_setting\n",
    "    )\n",
    "    \n",
    "    history = train_models_and_get_histories(\n",
    "        {ordering: model},\n",
    "        dset,\n",
    "        **base_training_setting\n",
    "    )\n",
    "    \n",
    "    return model, history[ordering]\n",
    "\n",
    "\n",
    "def determine_causal_ordering(data, base_model_instantiation_setting, base_training_setting):\n",
    "    all_models = {}\n",
    "    all_histories = {}\n",
    "\n",
    "    # Perform warm-up training\n",
    "    warmup_model = warm_up_oslow(data, base_model_instantiation_setting, base_training_setting)\n",
    "\n",
    "    def recursive_ordering(fixed_order):\n",
    "        if len(fixed_order) == 3:\n",
    "            return fixed_order\n",
    "\n",
    "        available_covariates = [i for i in range(3) if i not in fixed_order]\n",
    "        stage_key = '-'.join(map(str, fixed_order))\n",
    "\n",
    "        for start_covariate in available_covariates:\n",
    "            ordering = ''.join(map(str, fixed_order + [start_covariate] + [i for i in available_covariates if i != start_covariate]))\n",
    "            model_key = f\"{stage_key}-{start_covariate}\" if stage_key else f\"start_{start_covariate}\"\n",
    "\n",
    "            model, history = create_and_train_oslow_model_with_warmup(\n",
    "                ordering, data, warmup_model, base_model_instantiation_setting, base_training_setting\n",
    "            )\n",
    "            all_models[model_key] = model\n",
    "            all_histories[model_key] = history\n",
    "\n",
    "        stage_log_probs = {name: np.mean(history) for name, history in all_histories.items() if name.startswith(stage_key) or (not stage_key and name.startswith(\"start_\"))}\n",
    "        best_model = min(stage_log_probs, key=stage_log_probs.get)\n",
    "        best_covariate = int(best_model.split('_')[-1] if '_' in best_model else best_model.split('-')[-1])\n",
    "\n",
    "        new_fixed_order = fixed_order + [best_covariate]\n",
    "        return recursive_ordering(new_fixed_order)\n",
    "\n",
    "    causal_order = recursive_ordering([])\n",
    "    return causal_order, all_models, all_histories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model with ordering: 012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training model 012: 100%|██████████| 33/33 [00:07<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model with ordering: 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training model 102: 100%|██████████| 33/33 [00:07<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model with ordering: 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training model 201: 100%|██████████| 33/33 [00:06<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model with ordering: 012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training model 012: 100%|██████████| 33/33 [00:06<00:00,  5.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model with ordering: 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training model 201: 100%|██████████| 33/33 [00:06<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model with ordering: 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training model 201: 100%|██████████| 33/33 [00:06<00:00,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred causal order: [1, 0, 0]\n",
      "True causal order: [1, 0, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "causal_order, trained_models, training_histories = determine_causal_ordering(dset_sinusoidal)\n",
    "\n",
    "print(f\"Inferred causal order: {causal_order}\")\n",
    "print(f\"True causal order: [1, 0, 2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize negative log probabilities for each model\n",
    "plt.figure(figsize=(12, 6))\n",
    "for model_name, history in training_histories.items():\n",
    "    plt.plot(smooth_graph({model_name: history})[model_name], label=model_name)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Negative Log Probability')\n",
    "plt.title('Smoothed Negative Log Probabilities During Training')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
