{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with multiple datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Using GPU: NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "from notebook_setup import device, smooth_graph, create_new_set_of_models, train_models_and_get_histories, update_dict\n",
    "from oslow.models.oslow import OSlow\n",
    "from oslow.data.synthetic.graph_generator import GraphGenerator\n",
    "from oslow.data.synthetic.utils import RandomGenerator\n",
    "from oslow.data.synthetic.parametric import AffineParametericDataset\n",
    "from oslow.data.synthetic.nonparametric import AffineNonParametericDataset\n",
    "from oslow.models.normalization import ActNorm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "if torch.cuda.is_available():\n",
    "    # Set the device to GPU k\n",
    "    device = torch.device(\"cuda:5\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(device)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets generated:\n",
      "- sinusoidal\n",
      "- laplace_linear\n",
      "- nonparametric_affine\n",
      "- nonparametric_additive\n",
      "- nonparametric_almost_invertible\n"
     ]
    }
   ],
   "source": [
    "# Block 3: Generate datasets\n",
    "num_covariates = 3\n",
    "num_samples = 100\n",
    "true_ordering = [2, 0, 1]\n",
    "batch_size = 512\n",
    "lr = 0.005\n",
    "\n",
    "graph_generator = GraphGenerator(\n",
    "    num_nodes=num_covariates,\n",
    "    seed=0,\n",
    "    graph_type=\"full\",\n",
    "    enforce_ordering=true_ordering,\n",
    ")\n",
    "\n",
    "gaussian_noise_generator = RandomGenerator('normal', seed=10, loc=0, scale=1)\n",
    "laplace_noise_generator = RandomGenerator('laplace', seed=10, loc=0, scale=1)\n",
    "link_generator = RandomGenerator('uniform', seed=110, low=1, high=1)\n",
    "\n",
    "datasets = {\n",
    "    \"sinusoidal\": AffineParametericDataset(\n",
    "        num_samples=num_samples,\n",
    "        graph_generator=graph_generator,\n",
    "        noise_generator=gaussian_noise_generator,\n",
    "        link_generator=link_generator,\n",
    "        link=\"sinusoid\",\n",
    "        perform_normalization=False,\n",
    "    ),\n",
    "    # \"cubic\": AffineParametericDataset(\n",
    "    #     num_samples=num_samples,\n",
    "    #     graph_generator=graph_generator,\n",
    "    #     noise_generator=gaussian_noise_generator,\n",
    "    #     link_generator=link_generator,\n",
    "    #     link=\"cubic\",\n",
    "    #     perform_normalization=True,\n",
    "    # ),\n",
    "    \"laplace_linear\": AffineParametericDataset(\n",
    "        num_samples=num_samples,\n",
    "        graph_generator=graph_generator,\n",
    "        noise_generator=laplace_noise_generator,\n",
    "        link_generator=link_generator,\n",
    "        link=\"linear\",\n",
    "        perform_normalization=False,\n",
    "        additive=True,\n",
    "    ),\n",
    "    \"nonparametric_affine\": AffineNonParametericDataset(\n",
    "        num_samples=1000,\n",
    "        graph_generator=graph_generator,\n",
    "        noise_generator=gaussian_noise_generator,\n",
    "        invertibility_coefficient=0.0,\n",
    "        perform_normalization=False,\n",
    "        additive=False,\n",
    "    ),\n",
    "    \"nonparametric_additive\": AffineNonParametericDataset(\n",
    "        num_samples=1000,\n",
    "        graph_generator=graph_generator,\n",
    "        noise_generator=gaussian_noise_generator,\n",
    "        invertibility_coefficient=0.0,\n",
    "        perform_normalization=False,\n",
    "        additive=True,\n",
    "    ),\n",
    "    \"nonparametric_almost_invertible\": AffineNonParametericDataset(\n",
    "        num_samples=1000,\n",
    "        graph_generator=graph_generator,\n",
    "        noise_generator=gaussian_noise_generator,\n",
    "        invertibility_coefficient=1.0,\n",
    "        perform_normalization=False,\n",
    "        additive=False,\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"Datasets generated:\")\n",
    "for name in datasets.keys():\n",
    "    print(f\"- {name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Ordering algorithm\n",
    "\n",
    "See the determined_ordering function. This is a recursive algorithm to determine the causal ordering of covariates.\n",
    "\n",
    "* For each starting covariate, we will sample the remaining covariates to form complete permutations of length num_total_covariates by sampling uniformly without replacement. We will create and train a unique OSLow model for each permutation that we have sampled.\n",
    "* Once training has finished, for each starting covariate, calculate the average of the log probabilities of the data over all the OSLow models with that starting covariate.\n",
    "* The starting covariate used in the OSLow models achieving the lowest log probability on average (in expectation) indicates which covariate comes first.\n",
    "* Fix the first element and then continue this recursively until all the elements have been ordered.\n",
    "\n",
    "For example, if we have 3 variables [0, 1, 2], then for the starting covariate 0, we would have the models conditioned on permutations [0, 1, 2] and [0, 2, 1]. We would take the final log probability for the [0, 1, 2] model and the final log probability for the [0, 2, 1] model and find their average final log probability by taking their mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_permutations(remaining, num_samples=10):\n",
    "    \"\"\"\n",
    "    Generate an unbiased sample of permutations from the remaining covariates.\n",
    "\n",
    "    Args:\n",
    "    remaining (list or tuple): List of remaining covariates to permute.\n",
    "    num_samples (int): Number of permutation samples to generate.\n",
    "\n",
    "    Returns:\n",
    "    List[List[int]]: List of sampled permutations of the remaining covariates.\n",
    "    \"\"\"\n",
    "    if len(remaining) == 1:\n",
    "        return [[remaining[0]]] * num_samples\n",
    "    sampled_permutations = []\n",
    "    for _ in range(num_samples):\n",
    "        # Create a copy of the remaining list to shuffle\n",
    "        perm = list(remaining)\n",
    "        # Shuffle the list in-place\n",
    "        random.shuffle(perm)\n",
    "        sampled_permutations.append(perm)\n",
    "    \n",
    "    return sampled_permutations\n",
    "\n",
    "\n",
    "def create_oslow_model_with_ordering(ordering, additive=False, base_distribution=None):\n",
    "    if base_distribution is None:\n",
    "        base_distribution = torch.distributions.Normal(loc=0, scale=1)\n",
    "    \n",
    "    return OSlow(\n",
    "        in_features=len(ordering),\n",
    "        layers=[100, 100],\n",
    "        dropout=None,\n",
    "        residual=False,\n",
    "        activation=torch.nn.LeakyReLU(),\n",
    "        additive=additive,\n",
    "        num_transforms=1,\n",
    "        normalization=ActNorm,\n",
    "        base_distribution=base_distribution,\n",
    "        ordering=torch.tensor(ordering)\n",
    "    )\n",
    "\n",
    "def initialize_models_and_optimizers(determined_ordering, remaining_covariates, num_total_covariates, model_params):\n",
    "    \"\"\"\n",
    "    Initialize models, optimizers, and histories for all possible permutations of remaining covariates.\n",
    "\n",
    "    Args:\n",
    "    - determined_ordering: list of covariates that have already been ordered\n",
    "    - remaining_covariates: list of remaining covariates to consider\n",
    "    - num_total_covariates: total number of covariates in the dataset (int)\n",
    "    - dataset: the AffineParametricDataset or AffineNonParametricDataset to be used for training\n",
    "    - model_params: additional parameters for model creation\n",
    "\n",
    "    Returns:\n",
    "    - models: dictionary of OSlow models for each permutation\n",
    "    - histories: dictionary to store training histories for each model\n",
    "    - dataloader: DataLoader for the given dataset\n",
    "    \"\"\"\n",
    "    all_permutations = []\n",
    "    for i in range(len(remaining_covariates)):\n",
    "        start_covariate = remaining_covariates[i]\n",
    "        if i == 0:\n",
    "            permutation_remaining_covariates = remaining_covariates[1:]\n",
    "        elif i == len(remaining_covariates) - 1:\n",
    "            permutation_remaining_covariates = remaining_covariates[:i]\n",
    "        else:\n",
    "            permutation_remaining_covariates = remaining_covariates[:i] + remaining_covariates[i+1:]\n",
    "        \n",
    "        samples = sample_permutations(permutation_remaining_covariates, num_samples=10)\n",
    "        all_permutations.extend([[start_covariate] + sample for sample in samples])\n",
    "    # for each starting covariate, sample the permutations and then add this to a list of all the permutations\n",
    "    \n",
    "    models = {}\n",
    "    histories = {}\n",
    "\n",
    "    for perm in all_permutations:\n",
    "        full_perm = determined_ordering + perm\n",
    "        perm_key = tuple(full_perm)  # Use tuple as dictionary key\n",
    "\n",
    "        # Create model using the provided model_params\n",
    "        model = create_oslow_model_with_ordering(full_perm, **model_params).to(device)\n",
    "\n",
    "        if perm_key not in models:\n",
    "            models[perm_key] = []\n",
    "            histories[perm_key] = []\n",
    "\n",
    "        models[perm_key].append(model)\n",
    "        histories[perm_key].append([])\n",
    "\n",
    "        # Create initial permutation matrix\n",
    "        perm_matrix = torch.zeros((num_total_covariates, num_total_covariates))\n",
    "        for i, j in enumerate(full_perm):\n",
    "            perm_matrix[i, j] = 1\n",
    "        perm_matrix = perm_matrix.to(device)\n",
    "\n",
    "        # Store permutation matrix\n",
    "        models[perm_key][-1].perm_matrix = perm_matrix\n",
    "\n",
    "    return models, histories\n",
    "\n",
    "def determine_ordering(remaining_covariates, \n",
    "                       dataloader, \n",
    "                       model_params, \n",
    "                       training_params, \n",
    "                       determined_ordering=None, \n",
    "                       num_total_covariates=None, \n",
    "                       true_ordering=None, \n",
    "                       depth=0):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    - remaining_covariates: list of remaining covariates to consider\n",
    "    - dataloader: the AffineParametricDataset or AffineNonParametricDataset to be used for training\n",
    "    - model_params: additional parameters for model creation\n",
    "    - determined_ordering: list of covariates that have already been ordered\n",
    "    - num_total_covariates: total number of covariates in the dataset\n",
    "    - true_ordering: list of true ordering of covariates\n",
    "    - depth: current depth of recursion\n",
    "\n",
    "    Determine the correct causal ordering greedily by choosing the best covariate to come next.\n",
    "\n",
    "    Returns:\n",
    "    - determined_ordering: list of covariates in the determined ordering\n",
    "    \"\"\"\n",
    "    if determined_ordering is None:\n",
    "        determined_ordering = []\n",
    "    if num_total_covariates is None:\n",
    "        num_total_covariates = len(remaining_covariates)\n",
    "\n",
    "    if len(remaining_covariates) == 1:\n",
    "        return determined_ordering + remaining_covariates\n",
    "\n",
    "    print(f\"\\nCurrent stage of recursion at depth {depth}:\")\n",
    "    print(f\"  Ground truth ordering: {true_ordering}\")\n",
    "    print(f\"  Fixed ordering so far: {determined_ordering}\")\n",
    "    print(f\"  Remaining covariates: {remaining_covariates}\")\n",
    "\n",
    "    # Initialize models and optimizers for the remaining covariates\n",
    "    models, histories = initialize_models_and_optimizers(\n",
    "        determined_ordering, remaining_covariates, num_total_covariates, model_params\n",
    "    )\n",
    "\n",
    "    # Train each model sequentially\n",
    "    for perm_key in tqdm(models, desc=f\"Training models for {len(remaining_covariates)} remaining covariates\"):\n",
    "        for model_index in range(len(models[perm_key])):\n",
    "            model = models[perm_key][model_index]\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=training_params['lr'])\n",
    "            \n",
    "            for epoch in range(training_params['epoch_count']):\n",
    "                for batch, in dataloader:\n",
    "                    batch = batch.to(device)\n",
    "                    log_prob = model.log_prob(batch).mean()\n",
    "                    loss = -log_prob\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    histories[perm_key][model_index].append(log_prob.item())\n",
    "        \n",
    "    # Calculate average log probabilities for each starting covariate\n",
    "    starting_covariate_avg_log_probs = {}\n",
    "    for covariate in remaining_covariates:\n",
    "        relevant_perms = [perm for perm in models.keys() if perm[len(determined_ordering)] == covariate]\n",
    "        total_log_prob = 0\n",
    "        total_models = 0\n",
    "        \n",
    "        for perm in relevant_perms:\n",
    "            for model_history in histories[perm]:\n",
    "                # Add the final log probability of this model\n",
    "                total_log_prob += model_history[-1]\n",
    "                total_models += 1\n",
    "        \n",
    "        # Calculate the average log probability for this starting covariate\n",
    "        if total_models > 0:\n",
    "            avg_log_prob = total_log_prob / total_models\n",
    "        else:\n",
    "            avg_log_prob = float('-inf')  # or some other appropriate value\n",
    "        \n",
    "        starting_covariate_avg_log_probs[covariate] = avg_log_prob\n",
    "\n",
    "    # Choose the best starting covariate\n",
    "    next_covariate = max(starting_covariate_avg_log_probs, key=starting_covariate_avg_log_probs.get)\n",
    "    \n",
    "    # Sanity check\n",
    "    print(f\"\\nSanity Check Results at depth {depth}:\")\n",
    "    print(f\"  Average log probabilities for each starting covariate:\")\n",
    "    for covariate, avg_log_prob in starting_covariate_avg_log_probs.items():\n",
    "        print(f\"    Covariate {covariate}: {avg_log_prob}\")\n",
    "    print(f\"  Best covariate at this stage: {next_covariate}\")\n",
    "    print(f\"  Current ordering so far (including new covariate): {determined_ordering + [next_covariate]}\")\n",
    "    print(f\"  True ordering so far (including new covariate): {true_ordering[:depth+1]}\")\n",
    "    \n",
    "    remaining_covariates = [i for i in remaining_covariates if i != next_covariate]\n",
    "    return determine_ordering(remaining_covariates, dataloader, model_params, training_params, determined_ordering + [next_covariate], num_total_covariates, true_ordering, depth+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the tests for various datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing on sinusoidal dataset:\n",
      "\n",
      "Current stage of recursion at depth 0:\n",
      "  Ground truth ordering: [2, 0, 1]\n",
      "  Fixed ordering so far: []\n",
      "  Remaining covariates: [0, 1, 2]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 64, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_3968828/3802794552.py\", line 11, in forward\n    return torch.stack([model(x) for model in self.models])\nTypeError: expected Tensor as element 0 in argument 0, but got tuple\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 57\u001b[0m\n\u001b[1;32m     55\u001b[0m test_results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset_name \u001b[38;5;129;01min\u001b[39;00m datasets\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m---> 57\u001b[0m     test_results[dataset_name] \u001b[38;5;241m=\u001b[39m \u001b[43mrun_single_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 34\u001b[0m, in \u001b[0;36mrun_single_test\u001b[0;34m(dataset_name)\u001b[0m\n\u001b[1;32m     25\u001b[0m torch_dataset \u001b[38;5;241m=\u001b[39m TensorDataset(tensor_samples)\n\u001b[1;32m     26\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m     27\u001b[0m     torch_dataset, \n\u001b[1;32m     28\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mtraining_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m\n\u001b[1;32m     32\u001b[0m )\n\u001b[0;32m---> 34\u001b[0m discovered_ordering \u001b[38;5;241m=\u001b[39m \u001b[43mdetermine_ordering\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_covariates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrue_ordering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_ordering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_total_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_covariates\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue ordering: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrue_ordering\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiscovered ordering: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiscovered_ordering\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 60\u001b[0m, in \u001b[0;36mdetermine_ordering\u001b[0;34m(remaining_covariates, dataloader, model_params, training_params, determined_ordering, num_total_covariates, true_ordering, depth)\u001b[0m\n\u001b[1;32m     57\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Forward pass for all models\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m log_probs \u001b[38;5;241m=\u001b[39m \u001b[43mparallel_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization for each model\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, log_prob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(log_probs):\n",
      "File \u001b[0;32m~/miniconda3/envs/oslow/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/oslow/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:171\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    170\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 171\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/oslow/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:181\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/oslow/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:89\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     87\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m---> 89\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/oslow/lib/python3.10/site-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 64, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/amli/miniconda3/envs/oslow/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_3968828/3802794552.py\", line 11, in forward\n    return torch.stack([model(x) for model in self.models])\nTypeError: expected Tensor as element 0 in argument 0, but got tuple\n"
     ]
    }
   ],
   "source": [
    "# Block 6: Function to run test on a single dataset\n",
    "\n",
    "def run_single_test(dataset_name):\n",
    "    dataset = datasets[dataset_name]\n",
    "    print(f\"\\nTesting on {dataset_name} dataset:\")\n",
    "    \n",
    "    if dataset_name == \"laplace_linear\":\n",
    "        model_params = {\n",
    "            \"additive\": True,\n",
    "            \"base_distribution\": torch.distributions.Laplace(loc=0, scale=1)\n",
    "        }\n",
    "    elif \"nonparametric_additive\" in dataset_name:\n",
    "        model_params = {\"additive\": True}\n",
    "    else:\n",
    "        model_params = {}\n",
    "    \n",
    "    training_params = {\n",
    "        \"batch_size\": 512,\n",
    "        \"lr\": 0.005,\n",
    "        \"epoch_count\": 30\n",
    "    }\n",
    "\n",
    "    # Create dataloader from the dataset\n",
    "    tensor_samples = torch.tensor(dataset.samples.values).float().clone().detach()\n",
    "    torch_dataset = TensorDataset(tensor_samples)\n",
    "    dataloader = DataLoader(\n",
    "        torch_dataset, \n",
    "        batch_size=training_params['batch_size'], \n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    discovered_ordering = determine_ordering(\n",
    "        remaining_covariates=list(range(num_covariates)),\n",
    "        dataloader=dataloader,\n",
    "        model_params=model_params,\n",
    "        training_params=training_params,\n",
    "        true_ordering=true_ordering,\n",
    "        num_total_covariates=num_covariates\n",
    "    )\n",
    "    \n",
    "    print(f\"True ordering: {true_ordering}\")\n",
    "    print(f\"Discovered ordering: {discovered_ordering}\")\n",
    "    \n",
    "    return {\n",
    "        \"true_ordering\": true_ordering,\n",
    "        \"discovered_ordering\": discovered_ordering\n",
    "    }\n",
    "\n",
    "# You can now run tests on individual datasets like this:\n",
    "# result = run_single_test(\"sinusoidal\")\n",
    "\n",
    "# Run the tests\n",
    "test_results = {}\n",
    "for dataset_name in datasets.keys():\n",
    "    test_results[dataset_name] = run_single_test(dataset_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
