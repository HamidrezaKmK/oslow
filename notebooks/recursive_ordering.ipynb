{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Using GPU: NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from notebook_setup import device, smooth_graph, create_new_set_of_models, train_models_and_get_histories, update_dict\n",
    "from oslow.models.oslow import OSlow\n",
    "from oslow.data.synthetic.graph_generator import GraphGenerator\n",
    "from oslow.data.synthetic.utils import RandomGenerator\n",
    "from oslow.data.synthetic.parametric import AffineParametericDataset\n",
    "from oslow.models.normalization import ActNorm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from itertools import permutations\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "if torch.cuda.is_available():\n",
    "    # Set the device to GPU k\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(device)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a causal graph using the GraphGenerator class. Here, we specify the number of nodes (3) and enforce a specific ordering [1, 0, 2]. This graph will be used as the ground truth for our causal discovery experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_covariates = 3\n",
    "true_ordering = [2, 1, 0] # [1, 3, 0, 2, 4]\n",
    "graph_generator = GraphGenerator(\n",
    "    num_nodes=num_covariates,\n",
    "    seed=0,\n",
    "    graph_type=\"full\",\n",
    "    enforce_ordering=true_ordering,\n",
    ")\n",
    "graph = graph_generator.generate_dag()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we generate synthetic data based on the causal graph. We create an AffineParametericDataset \n",
    "with sinusoidal links between variables. This dataset will be used to train our OSlow models and \n",
    "test our causal discovery strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 50000\n",
    "gaussian_noise_generator = RandomGenerator('normal', seed=10, loc=0, scale=1)\n",
    "link_generator = RandomGenerator('uniform', seed=110, low=1, high=1)\n",
    "\n",
    "dset_sinusoidal = AffineParametericDataset(\n",
    "    num_samples=num_samples,\n",
    "    graph_generator=graph_generator,  # Not graph, requires a GraphGenerator object that generates the DAG\n",
    "    noise_generator=gaussian_noise_generator,\n",
    "    link_generator=link_generator,\n",
    "    link=\"sinusoid\",\n",
    "    perform_normalization=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell defines the settings for our OSlow models and their training process. We specify the model \n",
    "architecture (additive or not, number of transforms, normalization method) and training parameters \n",
    "(batch size, learning rate, number of epochs). These settings will be used for all OSlow models we create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_instantiation_setting = dict(\n",
    "    additive = False,\n",
    "    num_transforms = 1,\n",
    "    normalization = ActNorm,\n",
    "    base_distribution = torch.distributions.Normal(loc=0, scale=1),\n",
    "    use_standard_ordering=False,\n",
    ")\n",
    "\n",
    "base_training_setting = dict(\n",
    "    batch_size=512,\n",
    "    lr=0.005,\n",
    "    epoch_count=10,\n",
    "    use_standard_ordering=False,\n",
    ")\n",
    "batch_size = base_training_setting['batch_size']\n",
    "lr = base_training_setting['lr']\n",
    "epoch_count = base_training_setting['epoch_count']\n",
    "use_standard_ordering = base_training_setting['use_standard_ordering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_samples = torch.tensor(dset_sinusoidal.samples.values).float()\n",
    "torch_dataset = TensorDataset(tensor_samples)\n",
    "torch_dataloader = DataLoader(torch_dataset, batch_size=base_training_setting['batch_size'], shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check\n",
    "\n",
    "Check that the a model conditioned on the true ordering of covariates actually corresponds to the highest log-likelihood (lowest loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # comment to select the ones you want to plot\n",
    "# subset_to_consider = [\n",
    "#     \"sinusoidal\", # only show the last 0.1 of the epochs\n",
    "# ]\n",
    "# all_models_trained = {}\n",
    "# for key in subset_to_consider:\n",
    "#     print(\"key: \", key)\n",
    "#     print(\"dataset: \", dset_sinusoidal)\n",
    "#     print(\"all_models_trained: \", all_models_trained)\n",
    "#     # print(\"all_models_trained[key]: \", all_models_trained[key])\n",
    "#     dset = dset_sinusoidal\n",
    "#     all_models_trained[key] = create_new_set_of_models(**base_model_instantiation_setting)\n",
    "#     all_histories = train_models_and_get_histories(**base_training_setting, dset=dset, all_models=all_models_trained[key])\n",
    "\n",
    "#     smoothed_histories = smooth_graph(all_histories, window_size=100)\n",
    "#     # create two subplots and unpack the output array immediately\n",
    "#     plt.figure(figsize=(15, 5))\n",
    "#     plt.subplot(121)\n",
    "#     plt.title(f\"full loss graph {key}\")\n",
    "#     plt.xlabel(\"epochs\")\n",
    "#     plt.ylabel(\"loss\")\n",
    "#     for order in all_histories.keys():\n",
    "#         plt.plot(all_histories[order], label=order)\n",
    "#     plt.legend()\n",
    "#     plt.subplot(122)\n",
    "#     plt.xlabel(\"epochs\")\n",
    "#     plt.ylabel(\"loss\")\n",
    "#     for order in all_histories.keys():\n",
    "#         ending_portion = int(0.1 * len(smoothed_histories[order]))\n",
    "#         plt.plot(smoothed_histories[order][-ending_portion:], label=order)\n",
    "#     plt.title(f\"{key} ending portion smoothed\")\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_oslow_model_with_ordering(ordering):\n",
    "    return OSlow(\n",
    "        in_features=len(ordering),\n",
    "        layers=[100, 100],\n",
    "        dropout=None,\n",
    "        residual=False,\n",
    "        activation=torch.nn.LeakyReLU(),\n",
    "        additive=False,\n",
    "        num_transforms=1,\n",
    "        normalization=ActNorm,\n",
    "        base_distribution=torch.distributions.Normal(loc=0, scale=1),\n",
    "        ordering=torch.tensor(ordering)  # Pass the ordering here\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Ordering algorithm\n",
    "\n",
    "See the determined_ordering function. This is a recursive algorithm to determine the causal ordering of covariates.\n",
    "\n",
    "This is an example. Suppose we have 3 different covariates.\n",
    "* For each starting covariate, we will sample the remaining covariates to form complete permutations of length 3 by sampling uniformly without replacement. We will create and train a unique OSLow model for each permutation that we have sampled.\n",
    "* Once training has finished, for each starting covariate, calculate the average of the log probabilities of the data over all the OSLow models with that starting covariate.\n",
    "* The starting covariate used in the OSLow models achieving the lowest log probability on average (in expectation) indicates which covariate comes first.\n",
    "* Fix the first element and then continue this recursively until all the elements have been ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_permutations(remaining):\n",
    "    \"\"\"\n",
    "    From a list or tuple of remaining covariates, return a list of all possible permutations, each of which is a list.\n",
    "    \"\"\"\n",
    "    return [list(p) for p in permutations(remaining)]\n",
    "\n",
    "def initialize_models_and_optimizers(determined_ordering, remaining_covariates, num_total_covariates):\n",
    "    \"\"\"\n",
    "    Initialize models, optimizers, and histories for all possible permutations of remaining covariates.\n",
    "\n",
    "    Args:\n",
    "    - determined_ordering: list of covariates that have already been ordered\n",
    "    - remaining_covariates: list of remaining covariates to consider\n",
    "    - num_total_covariates: total number of covariates in the dataset\n",
    "\n",
    "    Returns:\n",
    "    - models: dictionary of OSlow models for each permutation\n",
    "    - optimizers: dictionary of optimizers for each model\n",
    "    - histories: dictionary to store training histories for each model\n",
    "    \"\"\"\n",
    "    all_permutations = sample_permutations(remaining_covariates)\n",
    "    models = {}\n",
    "    optimizers = {}\n",
    "    histories = {}\n",
    "\n",
    "    for perm in all_permutations:\n",
    "        full_perm = determined_ordering + perm\n",
    "        perm_key = tuple(full_perm)  # Use tuple as dictionary key\n",
    "\n",
    "        # Create model\n",
    "        model = create_oslow_model_with_ordering(full_perm).to(device)\n",
    "        models[perm_key] = model\n",
    "\n",
    "        # Create optimizer\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        optimizers[perm_key] = optimizer\n",
    "\n",
    "        # Initialize history\n",
    "        histories[perm_key] = []\n",
    "\n",
    "        # Create initial permutation matrix\n",
    "        perm_matrix = torch.zeros((num_total_covariates, num_total_covariates))\n",
    "        for i, j in enumerate(full_perm):\n",
    "            perm_matrix[i, j] = 1\n",
    "        perm_matrix = perm_matrix.to(device)\n",
    "\n",
    "        # Store permutation matrix\n",
    "        models[perm_key].perm_matrix = perm_matrix\n",
    "\n",
    "    return models, optimizers, histories\n",
    "\n",
    "\n",
    "def determine_ordering(remaining_covariates, determined_ordering=None, num_total_covariates=None, true_ordering=None, true_model=None, depth=0):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    - remaining_covariates: list of remaining covariates to consider\n",
    "    - determined_ordering: list of covariates that have already been ordered\n",
    "    - num_total_covariates: total number of covariates in the dataset (should be 3)\n",
    "    - true_ordering: list of true ordering of covariates\n",
    "    - true_model: a model that is conditioned on the true ordering\n",
    "    - depth: current depth of recursion\n",
    "\n",
    "    Output:\n",
    "    - determined_ordering: list of covariates in the determined ordering\n",
    "    \"\"\"\n",
    "    if determined_ordering is None:\n",
    "        determined_ordering = []\n",
    "    if num_total_covariates is None:\n",
    "        num_total_covariates = len(remaining_covariates)\n",
    "\n",
    "    if len(remaining_covariates) == 1:\n",
    "        return determined_ordering + remaining_covariates\n",
    "\n",
    "    print(f\"\\nCurrent stage of recursion:\")\n",
    "    print(f\"  Fixed ordering so far: {determined_ordering}\")\n",
    "    print(f\"  Remaining covariates: {remaining_covariates}\")\n",
    "\n",
    "    # Initialize models and optimizers for the remaining covariates\n",
    "    models, optimizers, histories = initialize_models_and_optimizers(determined_ordering, remaining_covariates, num_total_covariates)\n",
    "    \n",
    "    # Create true model only once at the start of recursion\n",
    "    if true_ordering is not None and true_model is None:\n",
    "        true_model = create_oslow_model_with_ordering(true_ordering).to(device)\n",
    "        true_optimizer = torch.optim.Adam(true_model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in tqdm(range(epoch_count), desc=f\"Training for {len(remaining_covariates)} remaining covariates\"):\n",
    "        for batch, in torch_dataloader:\n",
    "            batch = batch.to(device)\n",
    "            \n",
    "            for perm_key in models:\n",
    "                model = models[perm_key]\n",
    "                optimizer = optimizers[perm_key]\n",
    "\n",
    "                # log_prob = model.log_prob(batch, perm_mat=model.perm_matrix).mean()\n",
    "                log_prob = model.log_prob(batch).mean()\n",
    "                # print(f\"  Log probability for {perm_key}: {log_prob.item()} (default: {log_prob_default.item()})\")\n",
    "\n",
    "                loss = -log_prob\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                histories[perm_key].append(log_prob.item())\n",
    "            \n",
    "            # Train true ordering model only once at the start\n",
    "            if true_ordering is not None and true_model is not None and determined_ordering == []:\n",
    "                # true_perm_matrix = torch.zeros((num_total_covariates, num_total_covariates))\n",
    "                # for i, j in enumerate(true_ordering):\n",
    "                #     true_perm_matrix[i, j] = 1\n",
    "                # true_perm_matrix = true_perm_matrix.to(device)\n",
    "                \n",
    "                true_log_prob = true_model.log_prob(batch).mean()\n",
    "                # true_log_prob = true_model.log_prob(batch, perm_mat=true_perm_matrix).mean()\n",
    "                true_loss = -true_log_prob\n",
    "                \n",
    "                true_optimizer.zero_grad()\n",
    "                true_loss.backward()\n",
    "                true_optimizer.step()\n",
    "        \n",
    "    if determined_ordering == []:\n",
    "        print(\"Final log probability of true model after training: \", true_log_prob.item())\n",
    "\n",
    "    final_log_probs = {perm_key: histories[perm_key][-1] for perm_key in models}\n",
    "    best_perm_key = max(final_log_probs, key=final_log_probs.get)\n",
    "    next_covariate = best_perm_key[len(determined_ordering)]\n",
    "    \n",
    "    # Sanity check\n",
    "    if true_ordering is not None and true_model is not None:\n",
    "        print(f\"\\nSanity Check Results at depth {depth}:\")\n",
    "        print(f\"  Best found log probability: {max(final_log_probs.values())}\")\n",
    "        print(f\"  Best found permutation: {best_perm_key}\")\n",
    "        print(f\"  Current ordering so far (including new covariate): {determined_ordering + [next_covariate]}\")\n",
    "        print(f\"  True ordering so far (including new covariate): {true_ordering[:depth+1]}\")\n",
    "    \n",
    "    remaining_covariates = [i for i in remaining_covariates if i != next_covariate]\n",
    "    return determine_ordering(remaining_covariates, determined_ordering + [next_covariate], num_total_covariates, true_ordering, true_model, depth+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current stage of recursion:\n",
      "  Fixed ordering so far: []\n",
      "  Remaining covariates: [0, 1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training for 3 remaining covariates:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training for 3 remaining covariates: 100%|██████████| 10/10 [01:00<00:00,  6.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final log probability of true model after training:  -7.028384208679199\n",
      "\n",
      "Sanity Check Results at depth 0:\n",
      "  Best found log probability: -7.022699356079102\n",
      "  Best found permutation: (2, 1, 0)\n",
      "  Current ordering so far (including new covariate): [2]\n",
      "  True ordering so far (including new covariate): [2]\n",
      "\n",
      "Current stage of recursion:\n",
      "  Fixed ordering so far: [2]\n",
      "  Remaining covariates: [0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training for 2 remaining covariates: 100%|██████████| 10/10 [00:20<00:00,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sanity Check Results at depth 1:\n",
      "  Best found log probability: -7.013666152954102\n",
      "  Best found permutation: (2, 1, 0)\n",
      "  Current ordering so far (including new covariate): [2, 1]\n",
      "  True ordering so far (including new covariate): [2, 1]\n",
      "The full inferred causal ordering is: [2, 1, 0]\n",
      "The true causal ordering is: [2, 1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "discovered_ordering = determine_ordering(list(range(num_covariates)), true_ordering=true_ordering)\n",
    "print(f\"The full inferred causal ordering is: {discovered_ordering}\")\n",
    "print(f\"The true causal ordering is: {true_ordering}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
