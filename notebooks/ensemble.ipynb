{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from notebooks.notebook_setup import device, smooth_graph, create_new_set_of_models, train_models_and_get_histories, update_dict\n",
    "from oslow.models.oslow import OSlowTest\n",
    "from oslow.data.synthetic.graph_generator import GraphGenerator\n",
    "from oslow.data.synthetic.utils import RandomGenerator\n",
    "from oslow.data.synthetic.parametric import AffineParametericDataset\n",
    "from oslow.data.synthetic.nonparametric import AffineNonParametericDataset\n",
    "from oslow.models.normalization import ActNorm\n",
    "from oslow.training.trainer import Trainer\n",
    "from oslow.config import GumbelTopKConfig, BirkhoffConfig, GumbelSinkhornStraightThroughConfig, ContrastiveDivergenceConfig\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "device = 'cuda:2'\n",
    "print(device)\n",
    "\n",
    "num_samples = 1000\n",
    "permutation_batch_size = 128\n",
    "flow_batch_size = 128\n",
    "epochs = 500\n",
    "flow_lr = 0.0001\n",
    "perm_lr = 0.000001\n",
    "flow_freq = 1\n",
    "perm_freq = 0\n",
    "num_nodes = 4\n",
    "\n",
    "graph_generator = GraphGenerator(\n",
    "    num_nodes=num_nodes,\n",
    "    seed=12,\n",
    "    graph_type=\"full\",\n",
    "    enforce_ordering=[i for i in range(num_nodes)],\n",
    ")\n",
    "graph = graph_generator.generate_dag()\n",
    "\n",
    "# These generators are also needed to generate the data\n",
    "gaussian_noise_generator = RandomGenerator('normal', seed=30, loc=0, scale=1)\n",
    "link_generator = RandomGenerator('uniform', seed=1100, low=1, high=1)\n",
    "\n",
    "# parameteric with sin(x) + x non-linearity and softplus\n",
    "dset_sinusoidal = AffineParametericDataset(\n",
    "    num_samples=num_samples,\n",
    "    graph=graph,\n",
    "    noise_generator=gaussian_noise_generator,\n",
    "    link_generator=link_generator,\n",
    "    link=\"sinusoid\",\n",
    "    perform_normalization=False,\n",
    "    standard=True,\n",
    ")\n",
    "class CustomTensorDataset(torch.utils.data.Dataset):\n",
    "    r\"\"\"Dataset wrapping tensors.\n",
    "\n",
    "    Each sample will be retrieved by indexing tensors along the first dimension.\n",
    "\n",
    "    Args:\n",
    "        *tensors (Tensor): tensors that have the same size of the first dimension.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tensor: torch.Tensor) -> None:\n",
    "        self.tensor = tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.tensor[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensor)\n",
    "\n",
    "\n",
    "dataset = CustomTensorDataset(torch.tensor(dset_sinusoidal.samples.values).float())\n",
    "flow_dataloader = DataLoader(dataset, batch_size=flow_batch_size, shuffle=True)\n",
    "permutation_dataloader = DataLoader(dataset, batch_size=permutation_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m temperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m     36\u001b[0m birkhoff_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \n\u001b[0;32m---> 37\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mdag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mflow_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mperm_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpermutation_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mflow_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mpermutation_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperm_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mflow_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mtemperature_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mpermutation_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperm_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mflow_lr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConstantLR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mpermutation_lr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConstantLR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mpermutation_learning_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpermutation_learning_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mbirkhoff_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbirkhoff_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnotebooks\u001b[39m\u001b[38;5;124m\"\u001b[39m, entity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mordered-causal-discovery\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     54\u001b[0m            name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moslow-ensemble\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     55\u001b[0m             tags\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno-sigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     62\u001b[0m             ],)\n\u001b[1;32m     63\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/ocdaf/notebooks/../ocd/training/trainer.py:74\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, dag, flow_dataloader, perm_dataloader, flow_optimizer, permutation_optimizer, flow_frequency, permutation_frequency, max_epochs, flow_lr_scheduler, permutation_lr_scheduler, permutation_learning_config, birkhoff_config, temperature, temperature_scheduler, device, perform_final_buffer_search)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epochs \u001b[38;5;241m=\u001b[39m max_epochs\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m permutation_learning_kwargs \u001b[38;5;241m=\u001b[39m permutation_learning_config\u001b[38;5;241m.\u001b[39mmodel_dump()\n\u001b[1;32m     76\u001b[0m method \u001b[38;5;241m=\u001b[39m permutation_learning_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/data2/hamid/miniconda3/envs/oslow/lib/python3.10/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data2/hamid/miniconda3/envs/oslow/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/data2/hamid/miniconda3/envs/oslow/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/data2/hamid/miniconda3/envs/oslow/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/data2/hamid/miniconda3/envs/oslow/lib/python3.10/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/data2/hamid/miniconda3/envs/oslow/lib/python3.10/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from oslow.visualization.birkhoff import get_all_permutation_matrices\n",
    "from oslow.models.oslow import OSlow\n",
    "import wandb\n",
    "\n",
    "torch.random.manual_seed(101)\n",
    "model = OSlow(in_features=num_nodes,\n",
    "              layers=[128, 64, 128],\n",
    "              dropout=None,\n",
    "              residual=False,\n",
    "              activation=torch.nn.LeakyReLU(),\n",
    "              additive=False,\n",
    "              num_transforms=1,\n",
    "              normalization=ActNorm,\n",
    "              base_distribution=torch.distributions.Normal(loc=0, scale=1),\n",
    "              ordering=None)\n",
    "\n",
    "\n",
    "def flow_optimizer(params): return torch.optim.AdamW(params, lr=flow_lr)\n",
    "def perm_optimizer(params): return torch.optim.AdamW(params, lr=perm_lr)\n",
    "\n",
    "\n",
    "permutation_learning_config = GumbelTopKConfig(\n",
    "    num_samples=num_samples,\n",
    "    buffer_size=10,\n",
    "    buffer_update=10,\n",
    "    set_gamma_uniform=True,\n",
    ")\n",
    "\n",
    "\n",
    "# permutation_learning_config = GumbelSinkhornStraightThroughConfig(temp=0.1, iters=20)\n",
    "temperature_scheduler = 'constant'\n",
    "temperature = 1.0\n",
    "\n",
    "birkhoff_config = None \n",
    "trainer = Trainer(model=model,\n",
    "                  dag=graph,\n",
    "                  flow_dataloader=flow_dataloader,\n",
    "                  perm_dataloader=permutation_dataloader,\n",
    "                  flow_optimizer=flow_optimizer,\n",
    "                  permutation_optimizer=perm_optimizer,\n",
    "                  flow_frequency=flow_freq,\n",
    "                  temperature=temperature,\n",
    "                  temperature_scheduler=temperature_scheduler,\n",
    "                  permutation_frequency=perm_freq,\n",
    "                  max_epochs=epochs,\n",
    "                  flow_lr_scheduler=torch.optim.lr_scheduler.ConstantLR,\n",
    "                  permutation_lr_scheduler=torch.optim.lr_scheduler.ConstantLR,\n",
    "                  permutation_learning_config=permutation_learning_config,\n",
    "                  birkhoff_config=birkhoff_config,\n",
    "                  device=device)\n",
    "wandb.init(project=\"notebooks\", entity=\"ordered-causal-discovery\",\n",
    "           name='oslow-ensemble',\n",
    "            tags=[\n",
    "                permutation_learning_config.method,\n",
    "                f\"num_nodes-{num_nodes}\",\n",
    "                f\"epochs-{epochs}\",\n",
    "                f\"base-temperature-{temperature}\",\n",
    "                f\"temperature-scheduling-{temperature_scheduler}\",\n",
    "                \"no-sigmoid\",\n",
    "            ],)\n",
    "trainer.train()\n",
    "wandb.finish()\n",
    "\n",
    "ensemble_model = trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from oslow.visualization.birkhoff import get_all_permutation_matrices\n",
    "from oslow.evaluation import backward_relative_penalty\n",
    "model_fixed = {}\n",
    "ensemble_model = trainer.model\n",
    "# iterate over all the 24 permutations of [0, 1, 2, 3]\n",
    "for perm in get_all_permutation_matrices(num_nodes):\n",
    "    perm_list = torch.argmax(perm, dim=-1).cpu().numpy().tolist()\n",
    "    perm_list_name = ''.join([str(i) for i in perm_list])\n",
    "    \n",
    "    torch.random.manual_seed(101)\n",
    "    model_fixed[perm_list_name] = OSlow(in_features=num_nodes,\n",
    "                layers=[128, 64, 128],\n",
    "                dropout=None,\n",
    "                residual=False,\n",
    "                activation=torch.nn.LeakyReLU(),\n",
    "                additive=False,\n",
    "                num_transforms=1,\n",
    "                normalization=ActNorm,\n",
    "                base_distribution=torch.distributions.Normal(loc=0, scale=1),\n",
    "                ordering=None)\n",
    "\n",
    "\n",
    "    def flow_optimizer(params): return torch.optim.AdamW(params, lr=flow_lr)\n",
    "    def perm_optimizer(params): return torch.optim.AdamW(params, lr=perm_lr)\n",
    "\n",
    "\n",
    "    permutation_learning_config = GumbelTopKConfig(\n",
    "        num_samples=num_samples,\n",
    "        buffer_size=10,\n",
    "        buffer_update=10,\n",
    "        set_gamma_custom=[\n",
    "            perm_list\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    # permutation_learning_config = GumbelSinkhornStraightThroughConfig(temp=0.1, iters=20)\n",
    "    temperature_scheduler = 'constant'\n",
    "    temperature = 0.00000001\n",
    "\n",
    "    birkhoff_config = None\n",
    "    trainer = Trainer(model=model_fixed[perm_list_name],\n",
    "                    dag=graph,\n",
    "                    flow_dataloader=flow_dataloader,\n",
    "                    perm_dataloader=permutation_dataloader,\n",
    "                    flow_optimizer=flow_optimizer,\n",
    "                    permutation_optimizer=perm_optimizer,\n",
    "                    flow_frequency=flow_freq,\n",
    "                    temperature=temperature,\n",
    "                    temperature_scheduler=temperature_scheduler,\n",
    "                    permutation_frequency=perm_freq,\n",
    "                    max_epochs=epochs,\n",
    "                    flow_lr_scheduler=torch.optim.lr_scheduler.ConstantLR,\n",
    "                    permutation_lr_scheduler=torch.optim.lr_scheduler.ConstantLR,\n",
    "                    permutation_learning_config=permutation_learning_config,\n",
    "                    birkhoff_config=birkhoff_config,\n",
    "                    device=device)\n",
    "    wandb.init(project=\"notebooks\", entity=\"ordered-causal-discovery\",\n",
    "               name=f\"perm-{perm_list_name}\",\n",
    "                tags=[\n",
    "                    permutation_learning_config.method,\n",
    "                    f\"num_nodes-{num_nodes}\",\n",
    "                    f\"epochs-{epochs}\",\n",
    "                    f\"base-temperature-{temperature}\",\n",
    "                    f\"temperature-scheduling-{temperature_scheduler}\",\n",
    "                    \"no-sigmoid\",\n",
    "                ],)\n",
    "    trainer.train()\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation: 0123\n",
      "Log Prob: -3.8473739624023438\n",
      "Backward count: 0.0\n",
      "\n",
      "-----\n",
      "Permutation: 0132\n",
      "Log Prob: -3.4337422847747803\n",
      "Backward count: 0.16666666666666666\n",
      "\n",
      "-----\n",
      "Permutation: 0213\n",
      "Log Prob: -3.635986566543579\n",
      "Backward count: 0.16666666666666666\n",
      "\n",
      "-----\n",
      "Permutation: 0231\n",
      "Log Prob: -3.7021663188934326\n",
      "Backward count: 0.3333333333333333\n",
      "\n",
      "-----\n",
      "Permutation: 0312\n",
      "Log Prob: -4.121689796447754\n",
      "Backward count: 0.3333333333333333\n",
      "\n",
      "-----\n",
      "Permutation: 0321\n",
      "Log Prob: -3.761078119277954\n",
      "Backward count: 0.5\n",
      "\n",
      "-----\n",
      "Permutation: 1023\n",
      "Log Prob: -4.187782287597656\n",
      "Backward count: 0.16666666666666666\n",
      "\n",
      "-----\n",
      "Permutation: 1032\n",
      "Log Prob: -3.5865049362182617\n",
      "Backward count: 0.3333333333333333\n",
      "\n",
      "-----\n",
      "Permutation: 1203\n",
      "Log Prob: -3.78493070602417\n",
      "Backward count: 0.3333333333333333\n",
      "\n",
      "-----\n",
      "Permutation: 1230\n",
      "Log Prob: -3.8279385566711426\n",
      "Backward count: 0.5\n",
      "\n",
      "-----\n",
      "Permutation: 1302\n",
      "Log Prob: -3.7680699825286865\n",
      "Backward count: 0.5\n",
      "\n",
      "-----\n",
      "Permutation: 1320\n",
      "Log Prob: -3.9193217754364014\n",
      "Backward count: 0.6666666666666666\n",
      "\n",
      "-----\n",
      "Permutation: 2013\n",
      "Log Prob: -3.730792999267578\n",
      "Backward count: 0.3333333333333333\n",
      "\n",
      "-----\n",
      "Permutation: 2031\n",
      "Log Prob: -3.8056631088256836\n",
      "Backward count: 0.5\n",
      "\n",
      "-----\n",
      "Permutation: 2103\n",
      "Log Prob: -3.8052897453308105\n",
      "Backward count: 0.5\n",
      "\n",
      "-----\n",
      "Permutation: 2130\n",
      "Log Prob: -4.022151470184326\n",
      "Backward count: 0.6666666666666666\n",
      "\n",
      "-----\n",
      "Permutation: 2301\n",
      "Log Prob: -4.346264362335205\n",
      "Backward count: 0.6666666666666666\n",
      "\n",
      "-----\n",
      "Permutation: 2310\n",
      "Log Prob: -4.243209362030029\n",
      "Backward count: 0.8333333333333334\n",
      "\n",
      "-----\n",
      "Permutation: 3012\n",
      "Log Prob: -3.97737979888916\n",
      "Backward count: 0.5\n",
      "\n",
      "-----\n",
      "Permutation: 3021\n",
      "Log Prob: -3.857933282852173\n",
      "Backward count: 0.6666666666666666\n",
      "\n",
      "-----\n",
      "Permutation: 3102\n",
      "Log Prob: -3.830376148223877\n",
      "Backward count: 0.6666666666666666\n",
      "\n",
      "-----\n",
      "Permutation: 3120\n",
      "Log Prob: -4.084018230438232\n",
      "Backward count: 0.8333333333333334\n",
      "\n",
      "-----\n",
      "Permutation: 3201\n",
      "Log Prob: -4.125710487365723\n",
      "Backward count: 0.8333333333333334\n",
      "\n",
      "-----\n",
      "Permutation: 3210\n",
      "Log Prob: -3.9923770427703857\n",
      "Backward count: 1.0\n",
      "\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "all_perms = get_all_permutation_matrices(4)\n",
    "\n",
    "all_scores = []\n",
    "all_backward = []\n",
    "with torch.no_grad():\n",
    "  for perm in all_perms:\n",
    "        perm = perm.float().to(device)\n",
    "        all_log_probs = []\n",
    "        for x in flow_dataloader:\n",
    "              x = x.to(device)\n",
    "              all_log_probs.append(model.log_prob(x, perm.unsqueeze(0).repeat(x.shape[0], 1, 1)).mean().item())\n",
    "        perm_list = [x for x in torch.argmax(perm, dim=1).cpu().numpy().tolist()]\n",
    "        perm_list_formatted = ''.join([str(x) for x in perm_list])\n",
    "        score = sum(all_log_probs) / len(all_log_probs)\n",
    "        backward = backward_relative_penalty(perm_list, graph)\n",
    "        all_scores.append(score)\n",
    "        all_backward.append(backward)\n",
    "        print(f\"Permutation: {perm_list_formatted}\\nLog Prob: {score}\\nBackward count: {backward}\\n\")\n",
    "        print(\"-----\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(all_backward, all_scores)\n",
    "plt.xlabel(\"Backward Penalty\")\n",
    "plt.ylabel(\"Log Prob\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oslow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
