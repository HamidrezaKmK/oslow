{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from notebooks.notebook_setup import device, smooth_graph, create_new_set_of_models, train_models_and_get_histories, update_dict\n",
    "from oslow.models.oslow import OSlowTest\n",
    "from oslow.data.synthetic.graph_generator import GraphGenerator\n",
    "from oslow.data.synthetic.utils import RandomGenerator\n",
    "from oslow.data.synthetic.parametric import AffineParametericDataset\n",
    "from oslow.data.synthetic.nonparametric import AffineNonParametericDataset\n",
    "from oslow.models.normalization import ActNorm\n",
    "from oslow.training.trainer import Trainer\n",
    "from oslow.training.permutation_learning.buffered_methods import GumbelTopK\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "device = 'cuda:0'\n",
    "print(device)\n",
    "\n",
    "num_samples = 1000\n",
    "permutation_batch_size = 128\n",
    "flow_batch_size = 128\n",
    "epochs = 500\n",
    "flow_lr = 0.001\n",
    "perm_lr = 0.00001\n",
    "flow_freq = 1\n",
    "perm_freq = 0\n",
    "num_nodes = 4\n",
    "\n",
    "graph_generator = GraphGenerator(\n",
    "    num_nodes=num_nodes,\n",
    "    seed=12,\n",
    "    graph_type=\"full\",\n",
    "    enforce_ordering=[i for i in range(num_nodes)],\n",
    ")\n",
    "\n",
    "# These generators are also needed to generate the data\n",
    "gaussian_noise_generator = RandomGenerator('normal', seed=30, loc=0, scale=1)\n",
    "link_generator = RandomGenerator('uniform', seed=1100, low=1, high=1)\n",
    "\n",
    "# parameteric with sin(x) + x non-linearity and softplus\n",
    "dset_sinusoidal = AffineParametericDataset(\n",
    "    num_samples=num_samples,\n",
    "    graph_generator=graph_generator,\n",
    "    noise_generator=gaussian_noise_generator,\n",
    "    link_generator=link_generator,\n",
    "    link=\"sinusoid\",\n",
    "    perform_normalization=False,\n",
    "    standard=True,\n",
    ")\n",
    "class CustomTensorDataset(torch.utils.data.Dataset):\n",
    "    r\"\"\"Dataset wrapping tensors.\n",
    "\n",
    "    Each sample will be retrieved by indexing tensors along the first dimension.\n",
    "\n",
    "    Args:\n",
    "        *tensors (Tensor): tensors that have the same size of the first dimension.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tensor: torch.Tensor) -> None:\n",
    "        self.tensor = tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.tensor[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensor)\n",
    "\n",
    "\n",
    "dataset = CustomTensorDataset(torch.tensor(dset_sinusoidal.samples.values).float())\n",
    "flow_dataloader = DataLoader(dataset, batch_size=flow_batch_size, shuffle=True)\n",
    "permutation_dataloader = DataLoader(dataset, batch_size=permutation_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/fs01/home/vdblm/projects/CD/oslow/notebooks/wandb/run-20240521_103708-co35d9y2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ordered-causal-discovery/notebooks/runs/co35d9y2' target=\"_blank\">oslow-ensemble</a></strong> to <a href='https://wandb.ai/ordered-causal-discovery/notebooks' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ordered-causal-discovery/notebooks' target=\"_blank\">https://wandb.ai/ordered-causal-discovery/notebooks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ordered-causal-discovery/notebooks/runs/co35d9y2' target=\"_blank\">https://wandb.ai/ordered-causal-discovery/notebooks/runs/co35d9y2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No final phase!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>evaluation/avg_backward_penalty</td><td>▆▅▁▃▅▅▅▅▃▄▃▅▅▃▆▆▄▅▃▃▆▃▆▆▅▆▅▇▄▃▅▃▅▆▆▅▆▃█▆</td></tr><tr><td>evaluation/best_backward_penalty</td><td>▁▂▄▇▇▄▇▁▅▇▄▄▄▄▂▇▁▅▂▄▇▂▄▇▄▇▂▁▇▅▅▂▂▇▇▇▁▅█▅</td></tr><tr><td>flow_ensemble/loss</td><td>█▇▃▇▄▄▅▃▃▃▃▅▄▄▆▃▅▄▃▃▄▄▂▃▃▄▂▅▃▄▄▂▄▄▃▃▁▅▁▆</td></tr><tr><td>flow_ensemble/step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>permutation/temperature</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>499</td></tr><tr><td>evaluation/avg_backward_penalty</td><td>0.0</td></tr><tr><td>evaluation/best_backward_penalty</td><td>0.0</td></tr><tr><td>flow_ensemble/loss</td><td>4.55708</td></tr><tr><td>flow_ensemble/step</td><td>4000</td></tr><tr><td>permutation/temperature</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">oslow-ensemble</strong> at: <a href='https://wandb.ai/ordered-causal-discovery/notebooks/runs/co35d9y2' target=\"_blank\">https://wandb.ai/ordered-causal-discovery/notebooks/runs/co35d9y2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240521_103708-co35d9y2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from oslow.visualization.birkhoff import get_all_permutation_matrices\n",
    "from oslow.models.oslow import OSlow\n",
    "import wandb\n",
    "from oslow.training.permutation_learning.initialization import uniform_gamma_init_func\n",
    "\n",
    "\n",
    "torch.random.manual_seed(101)\n",
    "model = OSlow(in_features=num_nodes,\n",
    "              layers=[128, 64, 128],\n",
    "              dropout=None,\n",
    "              residual=False,\n",
    "              activation=torch.nn.LeakyReLU(),\n",
    "              additive=False,\n",
    "              num_transforms=1,\n",
    "              normalization=ActNorm,\n",
    "              base_distribution=torch.distributions.Normal(loc=0, scale=1),\n",
    "              ordering=None)\n",
    "\n",
    "\n",
    "def flow_optimizer(params): return torch.optim.AdamW(params, lr=flow_lr)\n",
    "def perm_optimizer(params): return torch.optim.AdamW(params, lr=perm_lr)\n",
    "\n",
    "\n",
    "# permutation_learning_config = GumbelTopKConfig(\n",
    "#     num_samples=num_samples,\n",
    "#     buffer_size=10,\n",
    "#     buffer_update=10,\n",
    "#     set_gamma_uniform=True,\n",
    "# )\n",
    "\n",
    "\n",
    "# permutation_learning_config = GumbelSinkhornStraightThroughConfig(temp=0.1, iters=20)\n",
    "temperature_scheduler = 'constant'\n",
    "temperature = 1.0\n",
    "\n",
    "perm_module = lambda in_features: GumbelTopK(in_features, num_samples=num_samples, buffer_size=10, buffer_update=10, initialization_function=uniform_gamma_init_func)\n",
    "\n",
    "birkhoff_config = None \n",
    "trainer = Trainer(model=model,\n",
    "                  dag=dset_sinusoidal.dag,\n",
    "                  flow_dataloader=flow_dataloader,\n",
    "                  perm_dataloader=permutation_dataloader,\n",
    "                  flow_optimizer=flow_optimizer,\n",
    "                  permutation_optimizer=perm_optimizer,\n",
    "                  flow_frequency=flow_freq,\n",
    "                  temperature=temperature,\n",
    "                  temperature_scheduler=temperature_scheduler,\n",
    "                  permutation_frequency=perm_freq,\n",
    "                  max_epochs=epochs,\n",
    "                  flow_lr_scheduler=torch.optim.lr_scheduler.ConstantLR,\n",
    "                  permutation_lr_scheduler=torch.optim.lr_scheduler.ConstantLR,\n",
    "                  permutation_learning_module=perm_module,\n",
    "                  device=device)\n",
    "wandb.init(project=\"notebooks\", entity=\"ordered-causal-discovery\",\n",
    "           name='oslow-ensemble',\n",
    "            tags=[\n",
    "                f\"num_nodes-{num_nodes}\",\n",
    "                f\"epochs-{epochs}\",\n",
    "                f\"base-temperature-{temperature}\",\n",
    "                f\"temperature-scheduling-{temperature_scheduler}\",\n",
    "                \"no-sigmoid\",\n",
    "            ],)\n",
    "trainer.train()\n",
    "wandb.finish()\n",
    "\n",
    "ensemble_model = trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %autoreload 2\n",
    "\n",
    "from oslow.visualization.birkhoff import get_all_permutation_matrices\n",
    "from oslow.evaluation import backward_relative_penalty\n",
    "\n",
    "# model_fixed = {}\n",
    "# ensemble_model = trainer.model\n",
    "# # iterate over all the 24 permutations of [0, 1, 2, 3]\n",
    "# for perm in get_all_permutation_matrices(num_nodes):\n",
    "#     perm_list = torch.argmax(perm, dim=-1).cpu().numpy().tolist()\n",
    "#     perm_list_name = ''.join([str(i) for i in perm_list])\n",
    "\n",
    "#     torch.random.manual_seed(101)\n",
    "#     model_fixed[perm_list_name] = OSlow(in_features=num_nodes,\n",
    "#                 layers=[128, 64, 128],\n",
    "#                 dropout=None,\n",
    "#                 residual=False,\n",
    "#                 activation=torch.nn.LeakyReLU(),\n",
    "#                 additive=False,\n",
    "#                 num_transforms=1,\n",
    "#                 normalization=ActNorm,\n",
    "#                 base_distribution=torch.distributions.Normal(loc=0, scale=1),\n",
    "#                 ordering=None)\n",
    "\n",
    "\n",
    "#     def flow_optimizer(params): return torch.optim.AdamW(params, lr=flow_lr)\n",
    "#     def perm_optimizer(params): return torch.optim.AdamW(params, lr=perm_lr)\n",
    "\n",
    "\n",
    "#     permutation_learning_config = GumbelTopKConfig(\n",
    "#         num_samples=num_samples,\n",
    "#         buffer_size=10,\n",
    "#         buffer_update=10,\n",
    "#         set_gamma_custom=[\n",
    "#             perm_list\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "\n",
    "#     # permutation_learning_config = GumbelSinkhornStraightThroughConfig(temp=0.1, iters=20)\n",
    "#     temperature_scheduler = 'constant'\n",
    "#     temperature = 0.00000001\n",
    "\n",
    "#     birkhoff_config = None\n",
    "#     trainer = Trainer(model=model_fixed[perm_list_name],\n",
    "#                     dag=graph,\n",
    "#                     flow_dataloader=flow_dataloader,\n",
    "#                     perm_dataloader=permutation_dataloader,\n",
    "#                     flow_optimizer=flow_optimizer,\n",
    "#                     permutation_optimizer=perm_optimizer,\n",
    "#                     flow_frequency=flow_freq,\n",
    "#                     temperature=temperature,\n",
    "#                     temperature_scheduler=temperature_scheduler,\n",
    "#                     permutation_frequency=perm_freq,\n",
    "#                     max_epochs=epochs,\n",
    "#                     flow_lr_scheduler=torch.optim.lr_scheduler.ConstantLR,\n",
    "#                     permutation_lr_scheduler=torch.optim.lr_scheduler.ConstantLR,\n",
    "#                     permutation_learning_config=permutation_learning_config,\n",
    "#                     birkhoff_config=birkhoff_config,\n",
    "#                     device=device)\n",
    "#     wandb.init(project=\"notebooks\", entity=\"ordered-causal-discovery\",\n",
    "#                name=f\"perm-{perm_list_name}\",\n",
    "#                 tags=[\n",
    "#                     permutation_learning_config.method,\n",
    "#                     f\"num_nodes-{num_nodes}\",\n",
    "#                     f\"epochs-{epochs}\",\n",
    "#                     f\"base-temperature-{temperature}\",\n",
    "#                     f\"temperature-scheduling-{temperature_scheduler}\",\n",
    "#                     \"no-sigmoid\",\n",
    "#                 ],)\n",
    "#     trainer.train()\n",
    "#     wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation: 0123\n",
      "Log Prob: -4.12761914730072\n",
      "Backward count: 0.0\n",
      "\n",
      "-----\n",
      "Permutation: 0132\n",
      "Log Prob: -4.20219761133194\n",
      "Backward count: 0.16666666666666666\n",
      "\n",
      "-----\n",
      "Permutation: 0213\n",
      "Log Prob: -4.242488324642181\n",
      "Backward count: 0.16666666666666666\n",
      "\n",
      "-----\n",
      "Permutation: 0231\n",
      "Log Prob: -4.463877320289612\n",
      "Backward count: 0.3333333333333333\n",
      "\n",
      "-----\n",
      "Permutation: 0312\n",
      "Log Prob: -4.284694015979767\n",
      "Backward count: 0.3333333333333333\n",
      "\n",
      "-----\n",
      "Permutation: 0321\n",
      "Log Prob: -4.509818196296692\n",
      "Backward count: 0.5\n",
      "\n",
      "-----\n",
      "Permutation: 1023\n",
      "Log Prob: -4.245047152042389\n",
      "Backward count: 0.16666666666666666\n",
      "\n",
      "-----\n",
      "Permutation: 1032\n",
      "Log Prob: -4.329052746295929\n",
      "Backward count: 0.3333333333333333\n",
      "\n",
      "-----\n",
      "Permutation: 1203\n",
      "Log Prob: -4.331453859806061\n",
      "Backward count: 0.3333333333333333\n",
      "\n",
      "-----\n",
      "Permutation: 1230\n",
      "Log Prob: -4.49785715341568\n",
      "Backward count: 0.5\n",
      "\n",
      "-----\n",
      "Permutation: 1302\n",
      "Log Prob: -4.390943646430969\n",
      "Backward count: 0.5\n",
      "\n",
      "-----\n",
      "Permutation: 1320\n",
      "Log Prob: -4.574305713176727\n",
      "Backward count: 0.6666666666666666\n",
      "\n",
      "-----\n",
      "Permutation: 2013\n",
      "Log Prob: -4.35506147146225\n",
      "Backward count: 0.3333333333333333\n",
      "\n",
      "-----\n",
      "Permutation: 2031\n",
      "Log Prob: -4.364917099475861\n",
      "Backward count: 0.5\n",
      "\n",
      "-----\n",
      "Permutation: 2103\n",
      "Log Prob: -4.46623694896698\n",
      "Backward count: 0.5\n",
      "\n",
      "-----\n",
      "Permutation: 2130\n",
      "Log Prob: -4.5364075899124146\n",
      "Backward count: 0.6666666666666666\n",
      "\n",
      "-----\n",
      "Permutation: 2301\n",
      "Log Prob: -4.400568425655365\n",
      "Backward count: 0.6666666666666666\n",
      "\n",
      "-----\n",
      "Permutation: 2310\n",
      "Log Prob: -4.584644675254822\n",
      "Backward count: 0.8333333333333334\n",
      "\n",
      "-----\n",
      "Permutation: 3012\n",
      "Log Prob: -4.241497457027435\n",
      "Backward count: 0.5\n",
      "\n",
      "-----\n",
      "Permutation: 3021\n",
      "Log Prob: -4.328740477561951\n",
      "Backward count: 0.6666666666666666\n",
      "\n",
      "-----\n",
      "Permutation: 3102\n",
      "Log Prob: -4.381081998348236\n",
      "Backward count: 0.6666666666666666\n",
      "\n",
      "-----\n",
      "Permutation: 3120\n",
      "Log Prob: -4.503998339176178\n",
      "Backward count: 0.8333333333333334\n",
      "\n",
      "-----\n",
      "Permutation: 3201\n",
      "Log Prob: -4.395419538021088\n",
      "Backward count: 0.8333333333333334\n",
      "\n",
      "-----\n",
      "Permutation: 3210\n",
      "Log Prob: -4.558944225311279\n",
      "Backward count: 1.0\n",
      "\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_perms = get_all_permutation_matrices(4)\n",
    "\n",
    "all_scores = []\n",
    "all_backward = []\n",
    "with torch.no_grad():\n",
    "    for perm in all_perms:\n",
    "        perm = perm.float().to(device)\n",
    "        all_log_probs = []\n",
    "        for x in flow_dataloader:\n",
    "            x = x.to(device)\n",
    "            all_log_probs.append(\n",
    "                model.log_prob(x, perm.unsqueeze(0).repeat(x.shape[0], 1, 1))\n",
    "                .mean()\n",
    "                .item()\n",
    "            )\n",
    "        perm_list = [x for x in torch.argmax(perm, dim=1).cpu().numpy().tolist()]\n",
    "        perm_list_formatted = \"\".join([str(x) for x in perm_list])\n",
    "        score = sum(all_log_probs) / len(all_log_probs)\n",
    "        backward = backward_relative_penalty(perm_list, dset_sinusoidal.dag)\n",
    "        all_scores.append(-score)\n",
    "        all_backward.append(backward)\n",
    "        print(\n",
    "            f\"Permutation: {perm_list_formatted}\\nLog Prob: {score}\\nBackward count: {backward}\\n\"\n",
    "        )\n",
    "        print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def latexify(fig_width, fig_height, font_size=7, legend_size=5, labelsize=7):\n",
    "    \"\"\"Set up matplotlib's RC params for LaTeX plotting.\"\"\"\n",
    "    params = {\n",
    "        \"backend\": \"ps\",\n",
    "        \"text.latex.preamble\": \"\\\\usepackage{amsmath,amsfonts,amssymb,amsthm, mathtools,times}\",\n",
    "        \"axes.labelsize\": font_size,\n",
    "        \"axes.titlesize\": font_size,\n",
    "        \"legend.fontsize\": legend_size,\n",
    "        \"xtick.labelsize\": labelsize,\n",
    "        \"ytick.labelsize\": labelsize,\n",
    "        \"text.usetex\": True,\n",
    "        \"figure.figsize\": [fig_width, fig_height],\n",
    "        \"font.family\": \"serif\",\n",
    "        \"xtick.minor.size\": 0.5,\n",
    "        \"xtick.major.pad\": 3,\n",
    "        \"xtick.minor.pad\": 3,\n",
    "        \"xtick.major.size\": 1,\n",
    "        \"ytick.minor.size\": 0.5,\n",
    "        \"ytick.major.pad\": 1.5,\n",
    "        \"ytick.major.size\": 1,\n",
    "    }\n",
    "\n",
    "    mpl.rcParams.update(params)\n",
    "    plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "COLORS = {\n",
    "    \"green\": \"#12f913\",\n",
    "    \"blue\": \"#0000ff\",\n",
    "    \"red\": \"#ff0000\",\n",
    "    \"pink\": \"#fb87c4\",\n",
    "    \"black\": \"#000000\",\n",
    "}\n",
    "\n",
    "LIGHT_COLORS = {\n",
    "    \"blue\": (0.237808, 0.688745, 1.0),\n",
    "    \"red\": (1.0, 0.519599, 0.309677),\n",
    "    \"green\": (0.0, 0.790412, 0.705117),\n",
    "    \"pink\": (0.936386, 0.506537, 0.981107),\n",
    "    \"yellow\": (0.686959, 0.690574, 0.0577502),\n",
    "    \"black\": \"#535154\",\n",
    "}\n",
    "\n",
    "DARK_COLORS = {\n",
    "    \"green\": \"#3E9651\",\n",
    "    \"red\": \"#CC2529\",\n",
    "    \"blue\": \"#396AB1\",\n",
    "    \"black\": \"#535154\",\n",
    "}\n",
    "\n",
    "GOLDEN_RATIO = (np.sqrt(5) - 1.0) / 2\n",
    "\n",
    "cm = 1 / 2.54\n",
    "FIG_WIDTH = 17 * cm\n",
    "FONT_SIZE = 10\n",
    "LEGEND_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    }
   ],
   "source": [
    "latexify(\n",
    "    FIG_WIDTH / 3,\n",
    "    FIG_WIDTH * 0.25,\n",
    "    font_size=LEGEND_SIZE,\n",
    "    legend_size=LEGEND_SIZE,\n",
    "    labelsize=6,\n",
    ")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(FIG_WIDTH / 3, FIG_WIDTH * 0.25))\n",
    "color_list = [\"red\", \"blue\", \"green\", \"pink\"]\n",
    "fill_colors = [\"red\", \"blue\", \"green\", \"pink\"]\n",
    "linestyles = [\"-\"] * 4\n",
    "\n",
    "ax.scatter(all_backward, all_scores, s=4, marker=\"*\", c=LIGHT_COLORS[\"blue\"])\n",
    "ax.set_xlabel(r\"CBC\")\n",
    "ax.set_ylabel(r\"Negative log-likelihood\")\n",
    "# hs = axes[0, 0].get_legend_handles_labels()[0]\n",
    "\n",
    "# fig.legend(hs, names, loc=\"upper center\", ncol=4)\n",
    "plt.subplots_adjust(left=0.15, bottom=0.17, right=0.95, top=0.95)\n",
    "\n",
    "fig.savefig(\"ensemble_four.pdf\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oslow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
