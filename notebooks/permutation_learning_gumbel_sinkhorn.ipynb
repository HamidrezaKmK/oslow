{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamid/ocdaf/notebooks/../ocd/data/synthetic/utils.py:44: RuntimeWarning: overflow encountered in exp\n",
      "  return np.where(x > threshold, x, np.log(1 + np.exp(x)))\n",
      "/home/hamid/ocdaf/notebooks/../ocd/data/synthetic/utils.py:44: RuntimeWarning: overflow encountered in exp\n",
      "  return np.where(x > threshold, x, np.log(1 + np.exp(x)))\n",
      "/home/hamid/ocdaf/notebooks/../ocd/data/synthetic/utils.py:44: RuntimeWarning: overflow encountered in exp\n",
      "  return np.where(x > threshold, x, np.log(1 + np.exp(x)))\n",
      "/home/hamid/ocdaf/notebooks/../ocd/data/synthetic/utils.py:44: RuntimeWarning: overflow encountered in exp\n",
      "  return np.where(x > threshold, x, np.log(1 + np.exp(x)))\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from notebooks.notebook_setup import device, smooth_graph, create_new_set_of_models, train_models_and_get_histories, update_dict\n",
    "from oslow.models.oslow import OSlowTest\n",
    "from oslow.data.synthetic.graph_generator import GraphGenerator\n",
    "from oslow.data.synthetic.utils import RandomGenerator\n",
    "from oslow.data.synthetic.parametric import AffineParametericDataset\n",
    "from oslow.data.synthetic.nonparametric import AffineNonParametericDataset\n",
    "from oslow.models.normalization import ActNorm\n",
    "from oslow.training.trainer import Trainer\n",
    "from oslow.config import GumbelTopKConfig, BirkhoffConfig, GumbelSinkhornStraightThroughConfig, ContrastiveDivergenceConfig\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print(device)\n",
    "\n",
    "num_samples = 128\n",
    "permutation_batch_size = 128\n",
    "flow_batch_size = 128\n",
    "epochs = 20000\n",
    "flow_lr = 0.005\n",
    "perm_lr = 0.005\n",
    "flow_freq = 1\n",
    "perm_freq = 4\n",
    "num_nodes = 10\n",
    "\n",
    "graph_generator = GraphGenerator(\n",
    "    num_nodes=num_nodes,\n",
    "    seed=12,\n",
    "    graph_type=\"full\",\n",
    "    enforce_ordering=[i for i in range(num_nodes)],\n",
    ")\n",
    "graph = graph_generator.generate_dag()\n",
    "\n",
    "# These generators are also needed to generate the data\n",
    "gaussian_noise_generator = RandomGenerator('normal', seed=30, loc=0, scale=1)\n",
    "link_generator = RandomGenerator('uniform', seed=1100, low=1, high=1)\n",
    "\n",
    "# parameteric with sin(x) + x non-linearity and softplus\n",
    "dset_sinusoidal = AffineParametericDataset(\n",
    "    num_samples=num_samples,\n",
    "    graph=graph,\n",
    "    noise_generator=gaussian_noise_generator,\n",
    "    link_generator=link_generator,\n",
    "    link=\"sinusoid\",\n",
    "    perform_normalization=False,\n",
    ")\n",
    "class CustomTensorDataset(torch.utils.data.Dataset):\n",
    "    r\"\"\"Dataset wrapping tensors.\n",
    "\n",
    "    Each sample will be retrieved by indexing tensors along the first dimension.\n",
    "\n",
    "    Args:\n",
    "        *tensors (Tensor): tensors that have the same size of the first dimension.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tensor: torch.Tensor) -> None:\n",
    "        self.tensor = tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.tensor[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensor)\n",
    "\n",
    "\n",
    "dataset = CustomTensorDataset(torch.tensor(dset_sinusoidal.samples.values).float())\n",
    "flow_dataloader = DataLoader(dataset, batch_size=flow_batch_size, shuffle=True)\n",
    "permutation_dataloader = DataLoader(dataset, batch_size=permutation_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "torch.random.manual_seed(42)\n",
    "model = OSlowTest(\n",
    "    in_features=num_nodes,\n",
    "    base_matrix=torch.eye(num_nodes),\n",
    ")\n",
    "\n",
    "\n",
    "def flow_optimizer(params): return torch.optim.Adam(params, lr=flow_lr)\n",
    "def perm_optimizer(params): return torch.optim.Adam(params, lr=perm_lr)\n",
    "\n",
    "\n",
    "# permutation_learning_config = GumbelTopKConfig(num_samples=num_samples)\n",
    "# permutation_learning_config = ContrastiveDivergenceConfig(num_samples=num_samples)\n",
    "permutation_learning_config = GumbelSinkhornStraightThroughConfig(\n",
    "    temp=0.1, iters=20)\n",
    "# permutation_learning_config = GumbelSinkhornStraightThroughConfig(temp=0.1, iters=20)\n",
    "for temperature_scheduler in ['linear', 'constant']:\n",
    "    temperature = 1.\n",
    "\n",
    "    birkhoff_config = None if num_nodes > 4 else BirkhoffConfig(\n",
    "        num_samples=100, frequency=1, print_legend=False)\n",
    "    trainer = Trainer(model=model,\n",
    "                      dag=graph,\n",
    "                      flow_dataloader=flow_dataloader,\n",
    "                      perm_dataloader=permutation_dataloader,\n",
    "                      flow_optimizer=flow_optimizer,\n",
    "                      permutation_optimizer=perm_optimizer,\n",
    "                      flow_frequency=flow_freq,\n",
    "                      temperature=temperature,\n",
    "                      temperature_scheduler=temperature_scheduler,\n",
    "                      permutation_frequency=perm_freq,\n",
    "                      max_epochs=epochs,\n",
    "                      flow_lr_scheduler=torch.optim.lr_scheduler.ConstantLR,\n",
    "                      permutation_lr_scheduler=torch.optim.lr_scheduler.ConstantLR,\n",
    "                      permutation_learning_config=permutation_learning_config,\n",
    "                      birkhoff_config=birkhoff_config,\n",
    "                      device=device)\n",
    "    wandb.init(project=\"notebooks\", entity=\"ordered-causal-discovery\",\n",
    "               tags=[\n",
    "                   permutation_learning_config.method,\n",
    "                   f\"num_nodes-{num_nodes}\",\n",
    "                   f\"epochs-{epochs}\",\n",
    "                   f\"base-temperature-{temperature}\",\n",
    "                   f\"temperature-scheduling-{temperature_scheduler}\",\n",
    "                   \"no-sigmoid\",\n",
    "               ],)\n",
    "    trainer.train()\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oslow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
